diff --git a/.gitignore b/.gitignore
index 1d2c4e3..e304a65 100644
--- a/.gitignore
+++ b/.gitignore
@@ -157,3 +157,4 @@ cython_debug/
 
 # End of https://www.toptal.com/developers/gitignore/api/python,jupyternotebooks
 
+./wandb
\ No newline at end of file
diff --git a/Visium_human_DLPFC_Spoint.ipynb b/Visium_human_DLPFC_Spoint.ipynb
index b9c0682..923492d 100644
--- a/Visium_human_DLPFC_Spoint.ipynb
+++ b/Visium_human_DLPFC_Spoint.ipynb
@@ -216,7 +216,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 6,
    "id": "f91509f1-991d-477d-98b0-f0ec74abc834",
    "metadata": {
     "execution": {
@@ -231,14 +231,54 @@
    },
    "outputs": [
     {
-     "ename": "TypeError",
-     "evalue": "init_model() got an unexpected keyword argument 'use_wandb'",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# deg - differentially expressed gene method\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#       this tells to focus on most informative genes and ignore the rest. t-test to find \"marker-genes\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#       sm_size - making 100,000 suedo spots \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m spoint_model \u001b[38;5;241m=\u001b[39m \u001b[43mSpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc_ad\u001b[49m\u001b[43m,\u001b[49m\u001b[43mst_ad\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcelltype_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcluster_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdeg_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt-test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msm_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Enable wandb\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mwandb_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspacel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Project name\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mwandb_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspoint-run1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Run name\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m)\u001b[49m\n",
-      "\u001b[0;31mTypeError\u001b[0m: init_model() got an unexpected keyword argument 'use_wandb'"
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Setting global seed: 42\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/scratch/harsha.vasamsetti/sample_env/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:373: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
+      "  warnings.warn(problem)\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "normalizing counts per cell\n",
+      "    finished (0:00:00)\n",
+      "normalizing counts per cell\n",
+      "    finished (0:00:00)\n",
+      "### Finding marker genes...\n",
+      "ranking genes\n",
+      "    finished: added to `.uns['rank_genes_groups']`\n",
+      "    'names', sorted np.recarray to be indexed by group ids\n",
+      "    'scores', sorted np.recarray to be indexed by group ids\n",
+      "    'logfoldchanges', sorted np.recarray to be indexed by group ids\n",
+      "    'pvals', sorted np.recarray to be indexed by group ids\n",
+      "    'pvals_adj', sorted np.recarray to be indexed by group ids (0:02:06)\n",
+      "cluster_label\n",
+      "Astro L1 FGFR3 FOS            200\n",
+      "Astro L1 FGFR3 MT1G           200\n",
+      "Astro L1-6 FGFR3 ETNPPL       200\n",
+      "Endo L2-5 CLDN5               200\n",
+      "Exc L2-3 LINC00507 RPL9P17    200\n",
+      "                             ... \n",
+      "Inh L6 SST NPY                124\n",
+      "Inh L1 ADARB2 DISP2           109\n",
+      "Inh L1-2 PVALB TAC1            91\n",
+      "VLMC L1-3 CYP1B1               38\n",
+      "Inh L6 LAMP5 ANKRD20A11P       28\n",
+      "Name: count, Length: 120, dtype: int64\n",
+      "### Used gene numbers: 5137\n",
+      "### Initializing sample probability\n",
+      "### Genetating simulated spatial data using scRNA data with mode: unbalance\n",
+      "### Genetating simulated spatial data using scRNA data with mode: sqrt\n",
+      "### Genetating simulated spatial data using scRNA data with mode: balance\n"
      ]
     }
    ],
@@ -299,7 +339,6 @@
       "TPU available: False, using: 0 TPU cores\n",
       "HPU available: False, using: 0 HPUs\n",
       "/scratch/harsha.vasamsetti/sample_env/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /scratch/harsha.vasamsetti/sample_env/lib/python3.10 ...\n",
-      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
       "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
       "/scratch/harsha.vasamsetti/sample_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "/scratch/harsha.vasamsetti/sample_env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
@@ -309,7 +348,7 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Epoch 100/100: 100%|██████████| 100/100 [03:17<00:00,  1.91s/it, v_num=1, train_loss_step=1.65e+3, train_loss_epoch=1.64e+3]"
+      "Epoch 100/100: 100%|██████████| 100/100 [03:08<00:00,  1.86s/it, v_num=1, train_loss_step=1.63e+3, train_loss_epoch=1.64e+3]"
      ]
     },
     {
@@ -323,14 +362,92 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Epoch 100/100: 100%|██████████| 100/100 [03:17<00:00,  1.97s/it, v_num=1, train_loss_step=1.65e+3, train_loss_epoch=1.64e+3]\n"
+      "Epoch 100/100: 100%|██████████| 100/100 [03:08<00:00,  1.89s/it, v_num=1, train_loss_step=1.63e+3, train_loss_epoch=1.64e+3]\n"
      ]
     },
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "Step 1078: Test inference loss=-0.532:  22%|██▏       | 1078/5000 [07:09<26:02,  2.51it/s]\n"
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mspecialized_boy\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Tracking run with wandb version 0.22.0"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Run data is saved locally in <code>/scratch/harsha.vasamsetti/SPACEL/wandb/run-20250924_081205-xbub6c3s</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Syncing run <strong><a href='https://wandb.ai/specialized_boy/spacel/runs/xbub6c3s' target=\"_blank\">spoint-run1</a></strong> to <a href='https://wandb.ai/specialized_boy/spacel' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View project at <a href='https://wandb.ai/specialized_boy/spacel' target=\"_blank\">https://wandb.ai/specialized_boy/spacel</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View run at <a href='https://wandb.ai/specialized_boy/spacel/runs/xbub6c3s' target=\"_blank\">https://wandb.ai/specialized_boy/spacel/runs/xbub6c3s</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "Step 679: Test inference loss=-0.527:  14%|█▎        | 679/5000 [04:31<28:47,  2.50it/s]\n"
      ]
     },
     {
@@ -341,10 +458,13 @@
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
       "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
       "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspoint_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n",
-      "File \u001b[0;32m/scratch/harsha.vasamsetti/SPACEL/SPACEL/Spoint/base_model.py:557\u001b[0m, in \u001b[0;36mSpointModel.train\u001b[0;34m(self, max_steps, save_mode, save_path, prefix, sm_step, st_step, test_step_gap, convergence, early_stop, early_stop_max, sm_lr, st_lr, batch_size, rec_w, infer_w, m_w, scvi_max_epochs, scvi_early_stopping, scvi_batch_size)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_scvi_latent(max_epochs\u001b[38;5;241m=\u001b[39mscvi_max_epochs, early_stopping\u001b[38;5;241m=\u001b[39mscvi_early_stopping, batch_size\u001b[38;5;241m=\u001b[39mscvi_batch_size)\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_dataset(batch_size)\n\u001b[0;32m--> 557\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43msm_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msm_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mst_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mst_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_step_gap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_step_gap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvergence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvergence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43msm_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msm_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mst_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mst_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrec_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrec_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_w\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mm_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm_w\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
-      "File \u001b[0;32m/scratch/harsha.vasamsetti/SPACEL/SPACEL/Spoint/base_model.py:488\u001b[0m, in \u001b[0;36mSpointModel.train_model\u001b[0;34m(self, max_steps, save_mode, save_path, prefix, sm_step, st_step, test_step_gap, convergence, early_stop, early_stop_max, sm_lr, st_lr, batch_size, rec_w, infer_w, m_w)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Training Spoint model.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03mTraining Spoint model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124;03m    ``None``\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_model()\n\u001b[0;32m--> 488\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model_by_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43msm_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msm_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mst_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mst_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_step_gap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_step_gap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvergence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvergence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43msm_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msm_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mst_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mst_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrec_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrec_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_w\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mm_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm_w\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
-      "File \u001b[0;32m/scratch/harsha.vasamsetti/SPACEL/SPACEL/Spoint/base_model.py:388\u001b[0m, in \u001b[0;36mSpointModel.train_model_by_step\u001b[0;34m(self, max_steps, save_mode, save_path, prefix, sm_step, st_step, test_step_gap, convergence, early_stop, early_stop_max, sm_lr, st_lr, rec_w, infer_w, m_w)\u001b[0m\n\u001b[1;32m    386\u001b[0m     st_train_total_loss, sm_train_rec_loss, st_train_rec_loss, st_train_mmd_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_st(sm_exp, st_exp, rec_w\u001b[38;5;241m=\u001b[39mrec_w, m_w\u001b[38;5;241m=\u001b[39mm_w)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sm_step):\n\u001b[0;32m--> 388\u001b[0m     sm_train_total_loss, sm_train_infer_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_sm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msm_exp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msm_proportion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_w\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m test_step_gap \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    391\u001b[0m     sm_test_exp, sm_test_proportion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msm_test_ds[\u001b[38;5;28mnext\u001b[39m(sm_test_iter)]\n",
-      "File \u001b[0;32m/scratch/harsha.vasamsetti/SPACEL/SPACEL/Spoint/base_model.py:303\u001b[0m, in \u001b[0;36mSpointModel.train_sm\u001b[0;34m(self, sm_data, sm_labels, infer_w)\u001b[0m\n\u001b[1;32m    301\u001b[0m     infer_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_infer_loss_func(sm_labels, sm_predictions)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 303\u001b[0m     infer_loss \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosine_infer_loss_func(sm_labels, sm_predictions)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    305\u001b[0m     infer_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrmse_loss_func(sm_labels, sm_predictions)\n",
+      "File \u001b[0;32m/scratch/harsha.vasamsetti/SPACEL/SPACEL/Spoint/base_model.py:623\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, max_steps, save_mode, save_path, prefix, sm_step, st_step, test_step_gap, convergence, early_stop, early_stop_max, sm_lr, st_lr, batch_size, rec_w, infer_w, m_w, scvi_max_epochs, scvi_early_stopping, scvi_batch_size)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Training Spoint model.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03mObtain latent feature from scVI then feed in Spoint model for training.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03m    ``None``\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 623\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tempfile\u001b[38;5;241m.\u001b[39mgettempdir() ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpoint_models_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m,localtime()))\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(save_path):\n\u001b[1;32m    625\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(save_path)\n",
+      "File \u001b[0;32m/scratch/harsha.vasamsetti/SPACEL/SPACEL/Spoint/base_model.py:554\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(self, max_steps, save_mode, save_path, prefix, sm_step, st_step, test_step_gap, convergence, early_stop, early_stop_max, sm_lr, st_lr, batch_size, rec_w, infer_w, m_w)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    518\u001b[0m     max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m     m_w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    534\u001b[0m ):\n\u001b[1;32m    535\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Training Spoint model.\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;124;03m    Training Spoint model.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m        max_steps: The max step of training. The training process will be stop when achive max step.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m        save_mode: A string determinates how the model is saved. It must be one of 'best' and 'all'.\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m        save_path: A string representing the path directory where the model is saved.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m        prefix: A string added to the prefix of file name of saved model.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m        convergence: The threshold of early stop.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m        early_stop: If True, turn on early stop.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m        early_stop_max: The max steps of loss difference less than convergence.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m        sm_lr: Learning rate for simulated data.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m        st_lr: Learning rate for spatial transcriptomic data.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m        disc_lr: Learning rate of discriminator.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m        batch_size: Batch size of the data be feeded in model once.\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m        rec_w: The weight of reconstruction loss.\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;124;03m        infer_w: The weig ht of inference loss.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m        m_w: The weight of MMD loss.\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m        ``None``\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_model()\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_model_by_step(\n\u001b[1;32m    560\u001b[0m         max_steps\u001b[38;5;241m=\u001b[39mmax_steps,\n\u001b[1;32m    561\u001b[0m         save_mode\u001b[38;5;241m=\u001b[39msave_mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    574\u001b[0m         m_w\u001b[38;5;241m=\u001b[39mm_w\n\u001b[1;32m    575\u001b[0m     )\n",
+      "File \u001b[0;32m/scratch/harsha.vasamsetti/SPACEL/SPACEL/Spoint/base_model.py:431\u001b[0m, in \u001b[0;36mtrain_model_by_step\u001b[0;34m(self, max_steps, save_mode, save_path, prefix, sm_step, st_step, test_step_gap, convergence, early_stop, early_stop_max, sm_lr, st_lr, rec_w, infer_w, m_w)\u001b[0m\n\u001b[1;32m    429\u001b[0m     sm_test_iter \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mcycle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msm_test_sampler)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m st_shuffle_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 431\u001b[0m     st_iter \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mcycle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mst_sampler)\n\u001b[1;32m    433\u001b[0m st_exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mst_ds[\u001b[38;5;28mnext\u001b[39m(st_iter)][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    434\u001b[0m sm_exp, sm_proportion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msm_train_ds[\u001b[38;5;28mnext\u001b[39m(sm_train_iter)]\n",
+      "File \u001b[0;32m/scratch/harsha.vasamsetti/SPACEL/SPACEL/Spoint/base_model.py:304\u001b[0m, in \u001b[0;36mtrain_st\u001b[0;34m(self, sm_data, st_data, rec_w, m_w)\u001b[0m\n\u001b[1;32m    302\u001b[0m st_rec_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_rec_loss_func(st_data, st_rec_data)\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosine_rec_loss_func(st_data, st_rec_data)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    303\u001b[0m mmd_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmmd_loss(sm_latent, st_latent)\n\u001b[0;32m--> 304\u001b[0m loss \u001b[38;5;241m=\u001b[39m rec_w\u001b[38;5;241m*\u001b[39msm_rec_loss \u001b[38;5;241m+\u001b[39m rec_w\u001b[38;5;241m*\u001b[39mst_rec_loss \u001b[38;5;241m+\u001b[39m m_w\u001b[38;5;241m*\u001b[39mmmd_loss\n\u001b[1;32m    305\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mst_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
+      "File \u001b[0;32m/scratch/harsha.vasamsetti/sample_env/lib/python3.10/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[0;32m/scratch/harsha.vasamsetti/sample_env/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[0;32m/scratch/harsha.vasamsetti/sample_env/lib/python3.10/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
       "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
      ]
     }
